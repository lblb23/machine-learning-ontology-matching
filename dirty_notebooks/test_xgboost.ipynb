{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET 1\n",
    "train_features = pd.read_csv('dataset1_train_features.csv')\n",
    "test_features = pd.read_csv('dataset1_test_features.csv')\n",
    "\n",
    "train_types = []\n",
    "\n",
    "for row in train_features['Type']:\n",
    "    if row == 'Class':\n",
    "        train_types.append(1)\n",
    "    else:\n",
    "        train_types.append(0)\n",
    "        \n",
    "train_features['Type_encode'] = train_types\n",
    "\n",
    "test_types = []\n",
    "\n",
    "for row in test_features['Type']:\n",
    "    if row == 'Class':\n",
    "        test_types.append(1)\n",
    "    else:\n",
    "        test_types.append(0)\n",
    "        \n",
    "test_features['Type_encode'] = test_types\n",
    "\n",
    "X_train = train_features.loc[:, 'Ngram1_Entity':'Type_encode']\n",
    "y_train = train_features['Match']\n",
    "\n",
    "X_test = test_features.loc[:, 'Ngram1_Entity':'Type_encode']\n",
    "y_test = test_features['Match']\n",
    "\n",
    "df_train = train_features.loc[:, 'Ngram1_Entity':'Type_encode']\n",
    "df_train['Match'] = train_features['Match']\n",
    "\n",
    "df_test = test_features.loc[:, 'Ngram1_Entity':'Type_encode']\n",
    "df_test['Match'] = test_features['Match']\n",
    "\n",
    "X_train = X_train.fillna(value=0)\n",
    "X_test = X_test.fillna(value=0)\n",
    "\n",
    "train = pd.read_csv('dataset1_train.csv')\n",
    "test = pd.read_csv('dataset1_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500000\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train.sample(n = N, replace = True), label=y_train.sample(n = N, replace = True))\n",
    "dtest = xgb.DMatrix(X_test.sample(n = N, replace = True), label=y_test.sample(n = N, replace = True))\n",
    "\n",
    "# min_child_weight 10, gamma 2.0, subsample 0.8, colsample_bytree 0.8\n",
    "# max_depth 5\n",
    "param = {'silent': 0,\n",
    "         'objective': 'binary:logistic',\n",
    "         'min_child_weight': 10,\n",
    "         'gamma': 2.0,\n",
    "         'subsample': 0.8,\n",
    "         'colsample_bytree': 0.8,\n",
    "         'max_depth': 5\n",
    "        }\n",
    "\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'logloss'\n",
    "\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "plst = param.items()\n",
    "\n",
    "num_round = 100\n",
    "start = time.time()\n",
    "bst = xgb.train(plst, dtrain, num_round, evallist, verbose_eval=True)\n",
    "end = time.time()\n",
    "print('Training time', end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_prob = bst.predict(dtest)\n",
    "end = time.time()\n",
    "print('Testing time', end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
